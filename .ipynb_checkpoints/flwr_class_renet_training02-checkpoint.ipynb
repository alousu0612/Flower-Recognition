{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1555986408120,
     "user": {
      "displayName": "蘇柏庄",
      "photoUrl": "",
      "userId": "02004252092897989161"
     },
     "user_tz": -480
    },
    "id": "OVK0fFOhfNR3",
    "outputId": "64d40ac9-ce44-4587-b282-dab6df9eea26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3161,
     "status": "ok",
     "timestamp": 1555986411379,
     "user": {
      "displayName": "蘇柏庄",
      "photoUrl": "",
      "userId": "02004252092897989161"
     },
     "user_tz": -480
    },
    "id": "gvnY0Kd5fO__",
    "outputId": "c3183193-5d10-4ce9-c266-dcbc5b85a3f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.models import Sequential, Model,load_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.python.keras.applications import VGG19, ResNet50, InceptionV3\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "35z0x_XffWo0"
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile('drive/My Drive/Colab Notebooks/image_data.zip', 'r')\n",
    "zip_ref.extractall('unzipped_folder') # unzip directory\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QG0ylaFXfYJz"
   },
   "outputs": [],
   "source": [
    "# base_path = 'Dataset/flowers/'\n",
    "base_path = 'unzipped_folder/train/'\n",
    "# test_path = 'Dataset/test/'\n",
    "test_path = 'unzipped_folder/test/'\n",
    "# daisy：菊花。 dandelion：蒲公英。 rose：玫瑰。 sunflower：向日葵。 tulip：郁金香。\n",
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fDVjPWsfZtr"
   },
   "outputs": [],
   "source": [
    "fnames = []\n",
    "for category in categories:\n",
    "    flower_folder = os.path.join(base_path, category)\n",
    "    file_names = os.listdir(flower_folder)\n",
    "    full_path = [os.path.join(flower_folder, file_name) for file_name in file_names]\n",
    "    fnames.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OZm755IfbLc"
   },
   "outputs": [],
   "source": [
    "# train, test = train_test_split(fnames[0], train_size=0.8)\n",
    "images = []\n",
    "for names in fnames:\n",
    "    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n",
    "    images.append(one_category_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18059,
     "status": "ok",
     "timestamp": 1555981113675,
     "user": {
      "displayName": "蘇柏庄",
      "photoUrl": "",
      "userId": "02004252092897989161"
     },
     "user_tz": -480
    },
    "id": "62aN4zcjfcQk",
    "outputId": "3f5dd1ba-f358-40a6-b457-3081101cdca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442,640 is the min shape for daisy\n",
      "436,500 is the min shape for dandelion\n",
      "404,500 is the min shape for rose\n",
      "400,640 is the min shape for sunflower\n",
      "407,1024 is the min shape for tulip\n"
     ]
    }
   ],
   "source": [
    "for i,imgs in enumerate(images):\n",
    "    shapes = [img.shape for img in imgs]\n",
    "    widths = [shape[0] for shape in shapes]\n",
    "    heights = [shape[1] for shape in shapes]\n",
    "    print('%d,%d is the min shape for %s' % (np.max(widths), np.max(heights), categories[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OVAUxznfeT9"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 400, 400\n",
    "\n",
    "# Apply resize to all images\n",
    "resized_images = []\n",
    "for i,imgs in enumerate(images):\n",
    "    resized_images.append([cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC) for img in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbiLbbQ9fkTE"
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "val_images = []\n",
    "for imgs in resized_images:\n",
    "    train, test = train_test_split(imgs, train_size=0.8, test_size=0.2)\n",
    "    train_images.append(train)\n",
    "    val_images.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21891,
     "status": "ok",
     "timestamp": 1555981117541,
     "user": {
      "displayName": "蘇柏庄",
      "photoUrl": "",
      "userId": "02004252092897989161"
     },
     "user_tz": -480
    },
    "id": "dM4P1uk2fle1",
    "outputId": "880045ba-087c-486a-8f6a-eb2a071865f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400, 549, 412, 390, 506]\n",
      "sum of train images: 2257\n",
      "[100, 138, 103, 98, 127]\n",
      "sum of val_images: 566\n"
     ]
    }
   ],
   "source": [
    "len_train_images = [len(imgs) for imgs in train_images]\n",
    "print(len_train_images)\n",
    "print('sum of train images:', np.sum(len_train_images))\n",
    "train_categories = np.zeros((np.sum(len_train_images)), dtype='uint8')\n",
    "for i in range(5):\n",
    "    if i is 0:\n",
    "        train_categories[:len_train_images[i]] = i\n",
    "    else:\n",
    "        train_categories[np.sum(len_train_images[:i]):np.sum(len_train_images[:i+1])] = i\n",
    "        \n",
    "len_val_images = [len(imgs) for imgs in val_images]\n",
    "print(len_val_images)\n",
    "print('sum of val_images:', np.sum(len_val_images))\n",
    "val_categories = np.zeros((np.sum(len_val_images)), dtype='uint8')\n",
    "for i in range(5):\n",
    "    if i is 0:\n",
    "        val_categories[:len_val_images[i]] = i\n",
    "    else:\n",
    "        val_categories[np.sum(len_val_images[:i]):np.sum(len_val_images[:i+1])] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJgM7K0kfoeT"
   },
   "outputs": [],
   "source": [
    "tmp_train_imgs = []\n",
    "tmp_val_imgs = []\n",
    "for imgs in train_images:\n",
    "    tmp_train_imgs += imgs\n",
    "for imgs in val_images:\n",
    "    tmp_val_imgs += imgs\n",
    "train_images = np.array(tmp_train_imgs)\n",
    "val_images = np.array(tmp_val_imgs)\n",
    "\n",
    "train_data = train_images.astype('float32')\n",
    "val_data = val_images.astype('float32')\n",
    "train_labels = np_utils.to_categorical(train_categories, len(categories))\n",
    "val_labels = np_utils.to_categorical(val_categories, len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRmJyW1gfsLV"
   },
   "outputs": [],
   "source": [
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(train_data)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(train_labels)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(val_data)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(val_labels)\n",
    "train_data = train_data[:3400]\n",
    "train_labels = train_labels[:3400]\n",
    "val_data = val_data[:860]\n",
    "val_labels = val_labels[:860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RubhbCYXfuus"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH_NO_TOP = 'drive/My Drive/Colab Notebooks/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "def create_model_from_ResNet50():\n",
    "\n",
    "    \"\"\"\n",
    "     Use ResNet-50 (this model's code is from https://www.kaggle.com/cokastefan/keras-resnet-50)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ResNet50(include_top=False, pooling='avg', weights=WEIGHTS_PATH_NO_TOP))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "    model.layers[0].trainable = True\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-3, momentum=0.90, nesterov=True), metrics=['acc']) # optimizer=(lr=0.001)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42822,
     "status": "ok",
     "timestamp": 1555981138507,
     "user": {
      "displayName": "蘇柏庄",
      "photoUrl": "",
      "userId": "02004252092897989161"
     },
     "user_tz": -480
    },
    "id": "xkasYT1sfyF0",
    "outputId": "1b1bf2c5-cca0-45a5-cac5-d291c8fa38b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 29,907,845\n",
      "Trainable params: 29,844,485\n",
      "Non-trainable params: 63,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ResNet50 = create_model_from_ResNet50()\n",
    "model_ResNet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iv4RmwXufzUV"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 8\n",
    "# epochs1 = 50\n",
    "# epochs2 = 20\n",
    "epochs3 = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nccKW5POf2hM"
   },
   "outputs": [],
   "source": [
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    val_data,\n",
    "    val_labels,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1271494,
     "status": "ok",
     "timestamp": 1555864332775,
     "user": {
      "displayName": "蘇柏庄",
      "photoUrl": "",
      "userId": "02004252092897989161"
     },
     "user_tz": -480
    },
    "id": "rxzcdlWSf3q8",
    "outputId": "1aee693f-855e-49e2-a956-df69415f7f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "20/36 [===============>..............] - ETA: 5s - loss: 2.5576 - acc: 0.2156"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model_ResNet50_info = model_ResNet50.fit_generator(\n",
    "    generator=train_generator, \n",
    "    steps_per_epoch=len(train_data)/(batch_size),   # -> 106 # images 3392 = steps * batch_size = 106 * 32 \n",
    "    epochs=epochs3, \n",
    "    validation_steps=len(val_data)/(batch_size), # -> 26 # images 832 = steps * batch_size = 26 * 32\n",
    "    validation_data=val_generator, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print ('\\n model_ResNet50 took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, epochs3) )\n",
    "model_ResNet50.save('drive/My Drive/Colab Notebooks/Models/reset_50_training_sgd03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lwc3n3-ff7Kl"
   },
   "outputs": [],
   "source": [
    "# Plots for training and testing process: loss and accuracy\n",
    "\n",
    "def plot_model_history(model_name, history, epochs):\n",
    "  \n",
    "  print(model_name)\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  \n",
    "  # summarize history for accuracy\n",
    "  plt.subplot(1, 2 ,1)\n",
    "  plt.plot(np.arange(0, len(history['acc'])), history['acc'], 'r')\n",
    "  plt.plot(np.arange(1, len(history['val_acc'])+1), history['val_acc'], 'g')\n",
    "  plt.xticks(np.arange(0, epochs+1, epochs/10))\n",
    "  plt.title('Training Accuracy vs. Validation Accuracy')\n",
    "  plt.xlabel('Num of Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend(['train', 'validation'], loc='best')\n",
    "  \n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(np.arange(1, len(history['loss'])+1), history['loss'], 'r')\n",
    "  plt.plot(np.arange(1, len(history['val_loss'])+1), history['val_loss'], 'g')\n",
    "  plt.xticks(np.arange(0, epochs+1, epochs/10))\n",
    "  plt.title('Training Loss vs. Validation Loss')\n",
    "  plt.xlabel('Num of Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend(['train', 'validation'], loc='best')\n",
    "  \n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PKLIg_YMf81A"
   },
   "outputs": [],
   "source": [
    "plot_model_history('model_ResNet50', model_ResNet50_info.history, epochs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJRyavQCf-nF"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 400, 400\n",
    "test_path = './data/test/'\n",
    "\n",
    "\n",
    "test_images = []\n",
    "test_ids = []\n",
    "for img in os.listdir(test_path):\n",
    "    path = os.path.join(test_path, img)\n",
    "    img_id = img.split('.')[0]\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC)\n",
    "    img = np.reshape(img, (img_width, img_height, 3))\n",
    "    img = img/255.\n",
    "    test_images.append(np.array(img))\n",
    "    test_ids.append(np.array(img_id))\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_data = test_images.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pSwHSJAgAth"
   },
   "outputs": [],
   "source": [
    "model_ResNet50 = load_model('./reset_50_training_sgd03.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ygz_6DTrgFp1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submission = pd.DataFrame(model_ResNet50.predict_classes(test_data, verbose=0))\n",
    "submission.columns = ['flower_class']\n",
    "submission['id'] = test_ids\n",
    "submission = submission[['id', 'flower_class']]\n",
    "submission = submission.sort_values(by=['id'])\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ioj3tJ-kgH1y"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQr-2SswlecL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "flwr_class_renet_training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
